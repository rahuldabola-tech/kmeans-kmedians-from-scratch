# K-Means and K-Medians from Scratch

## Overview
From-scratch implementation of K-Means and K-Medians clustering to understand
unsupervised learning, distance metrics, and robustness to outliers.

## Key Concepts
- Unsupervised learning
- Euclidean vs Manhattan distance
- Sensitivity to outliers
- Iterative optimization & convergence

## Algorithm
1. Initialize centroids
2. Assign points to nearest centroid
3. Update centroids (mean / median)
4. Repeat until convergence

## Experiments
- Synthetic data clustering
- Outlier robustness analysis
- Comparison with sklearn
- Elbow method for choosing k

## Results & Insights
- K-Means works well on clean data
- K-Medians is more robust to outliers
- Initialization and distance choice matter
